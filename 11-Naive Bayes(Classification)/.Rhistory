install.packages("caTools")
library(caTools)
#divide dataset into training and testing
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# Plantilla para el pre procesado de datos
#import dataset
dataset = read.csv("Data.csv")
#cleaning NAs
dataset$Age=ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
dataset$Salary=ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
#transforming categorical data
dataset$Country=factor(dataset$Country,
levels=c("France","Spain","Germany"),
labels=c(1,2,3))
dataset$Purchased=factor(dataset$Purchased,
levels=c("No","Yes"),
labels=c(0,1))
#divide dataset into training and testing
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# Plantilla para el pre procesado de datos
#import dataset
dataset = read.csv("Data.csv")
#cleaning NAs
dataset$Age=ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
dataset$Salary=ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
#transforming categorical data
dataset$Country=factor(dataset$Country,
levels=c("France","Spain","Germany"),
labels=c(1,2,3))
dataset$Purchased=factor(dataset$Purchased,
levels=c("No","Yes"),
labels=c(0,1))
#divide dataset into training and testing
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# Plantilla para el pre procesado de datos
#import dataset
dataset = read.csv("Data.csv")
#cleaning NAs
dataset$Age=ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
dataset$Salary=ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
#transforming categorical data
dataset$Country=factor(dataset$Country,
levels=c("France","Spain","Germany"),
labels=c(1,2,3))
dataset$Purchased=factor(dataset$Purchased,
levels=c("No","Yes"),
labels=c(0,1))
#divide dataset into training and testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
training_set = subset(dataset, split==TRUE)
testing_set = subset(dataset, split==FALSE)
setwd("A:/Asus/Documents/UDEMYCOURSES/Machine Learning A to Z/Practicas/8-K-Nearest Neighbours")
#import dataset
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#divide dataset into training and testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split==TRUE)
testing_set = subset(dataset, split==FALSE)
training_set_n = subset(dataset, split==TRUE)
testing_set_n = subset(dataset, split==FALSE)
#Scaling values
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
library(class)
y_pred = knn(train = training_set[,-3],
test = testing_set[,-3],
cl = training_set[,3],
k = 5)
y_pred
cm = table(testing_set[,3], y_pred)
cm
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
# prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = knn(train = training_set[,-3],
test = testing_set[,-3],
cl = training_set[,3],
k = 5)
plot(set[, -3],
main = 'KNN (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = testing_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
# prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = knn(train = training_set[,-3],
test = testing_set[,-3],
cl = training_set[,3],
k = 5)
plot(set[, -3],
main = 'KNN (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = testing_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
# prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = knn(train = training_set[,-3],
test = testing_set[,-3],
cl = training_set[,3],
k = 5)
plot(set[, -3],
main = 'KNN (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Training set results
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
# prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = knn(train = training_set[,-3],
test = grid_set,
cl = training_set[,3],
k = 5)
plot(set[, -3],
main = 'KNN (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
setwd("A:/Asus/Documents/UDEMYCOURSES/Machine Learning A to Z/Practicas/9-Suport Vector Machine (SVM Classification)")
setwd("A:/Asus/Documents/UDEMYCOURSES/Machine Learning A to Z/Practicas/9-Suport Vector Machine (SVM Classification)")
#import dataset
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#divide dataset into training and testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split==TRUE)
testing_set = subset(dataset, split==FALSE)
training_set_n = subset(dataset, split==TRUE)
testing_set_n = subset(dataset, split==FALSE)
#Scaling values
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
#import dataset
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#divide dataset into training and testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split==TRUE)
testing_set = subset(dataset, split==FALSE)
training_set_n = subset(dataset, split==TRUE)
testing_set_n = subset(dataset, split==FALSE)
#Scaling values
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
#Ajustar el clasificador de regresion logistica con el conjunto de entrenamiento
library(e1071)
svm?
svm?
!svm
svm
?svm
classifier = svm(formula = dataset$Purchased ~ .,
data = training_set,
type = 'C-classification',
kernel = 'linear')
#import dataset
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#divide dataset into training and testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split==TRUE)
testing_set = subset(dataset, split==FALSE)
training_set_n = subset(dataset, split==TRUE)
testing_set_n = subset(dataset, split==FALSE)
#Scaling values
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
#Ajustar el clasificador de regresion logistica con el conjunto de entrenamiento
library(e1071)
classifier = svm(formula = dataset$Purchased ~ .,
data = training_set,
type = 'C-classification',
kernel = 'linear')
View(dataset)
View(dataset)
View(testing_set)
View(testing_set)
library(e1071)
classifier = svm(formula = Purchased ~ .,
data = training_set,
type = 'C-classification',
kernel = 'linear')
#Prediccion deos resultados del conjunto de testing
prob_pred = predict(classifier, type = "response", newdata = testing_set[,-3])
#Prediccion deos resultados del conjunto de testing
y_pred = predict(classifier, newdata = testing_set[,-3])
cm = table(testing_set[,3], y_pred)
cm
# Visualising the Training set results
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM classification (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Training set results
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM classification (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Test set results
set = testing_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM classification (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
setwd("A:/Asus/Documents/UDEMYCOURSES/Machine Learning A to Z/Practicas/10-Kernel SVM")
#import dataset
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#divide dataset into training and testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split==TRUE)
testing_set = subset(dataset, split==FALSE)
training_set_n = subset(dataset, split==TRUE)
testing_set_n = subset(dataset, split==FALSE)
#Scaling values
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
?svm
#Ajustar el clasificador de regresion logistica con el conjunto de entrenamiento
library(e1071)
seed(123)
classifier = svm(formula = Purchased ~ .,
data = training_set,
type = 'C-classification',
kernel = 'radial basis')
library(e1071)
classifier = svm(formula = Purchased ~ .,
data = training_set,
type = 'C-classification',
kernel = 'radial basis')
library(e1071)
classifier = svm(formula = Purchased ~ .,
data = training_set,
type = 'C-classification',
kernel = 'radial')
#Prediccion deos resultados del conjunto de testing
#prob_pred = predict(classifier, type = "response", newdata = testing_set[,-3])#solo para logistica
#y_pred = ifelse(prob_pred > 0.5, 1, 0)
#para las demas
y_pred = predict(classifier, newdata = testing_set[,-3])
#Crear la matriz de confusiones
cm = table(testing_set[,3], y_pred)
cm
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
#solo para logistica
#prob_set = predict(classifier, type = 'response', newdata = grid_set)
#y_grid = ifelse(prob_set > 0.5, 1, 0)
##Para las demas
#y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Training set results
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
#solo para logistica
#prob_set = predict(classifier, type = 'response', newdata = grid_set)
#y_grid = ifelse(prob_set > 0.5, 1, 0)
##Para las demas
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Test set results
set = testing_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
#solo para logistica
#prob_set = predict(classifier, type = 'response', newdata = grid_set)
#y_grid = ifelse(prob_set > 0.5, 1, 0)
##Para las demas
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'Kernel SVM Classification (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
setwd("A:/Asus/Documents/UDEMYCOURSES/Machine Learning A to Z/Practicas/11-Naive Bayes")
?naiveBayes
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#divide dataset into training and testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split==TRUE)
testing_set = subset(dataset, split==FALSE)
training_set_n = subset(dataset, split==TRUE)
testing_set_n = subset(dataset, split==FALSE)
#Scaling values
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
#Ajustar el clasificador de regresion logistica con el conjunto de entrenamiento
library(e1071)
classifier = naiveBayes(formula = Purchased ~ .,
data = dataset)
#Prediccion deos resultados del conjunto de testing
#prob_pred = predict(classifier, type = "response", newdata = testing_set[,-3])#solo para logistica
#y_pred = ifelse(prob_pred > 0.5, 1, 0)
#para las demas
y_pred = predict(classifier, newdata = testing_set[,-3])
y_pred
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#divide dataset into training and testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split==TRUE)
testing_set = subset(dataset, split==FALSE)
training_set_n = subset(dataset, split==TRUE)
testing_set_n = subset(dataset, split==FALSE)
#Scaling values
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
#Ajustar el clasificador de regresion logistica con el conjunto de entrenamiento
library(e1071)
classifier = naiveBayes(formula = Purchased ~ .,
data = training_set)
#Prediccion deos resultados del conjunto de testing
#prob_pred = predict(classifier, type = "response", newdata = testing_set[,-3])#solo para logistica
#y_pred = ifelse(prob_pred > 0.5, 1, 0)
#para las demas
y_pred = predict(classifier, newdata = testing_set[,-3])
y_pred
#Crear la matriz de confusiones
cm = table(testing_set[,3], y_pred)
cm
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
#solo para logistica
#prob_set = predict(classifier, type = 'response', newdata = grid_set)
#y_grid = ifelse(prob_set > 0.5, 1, 0)
##Para las demas
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'Naive Bayes Classification (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
