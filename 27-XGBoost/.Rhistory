install.packages("caTools")
library(caTools)
#divide dataset into training and testing
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# Plantilla para el pre procesado de datos
#import dataset
dataset = read.csv("Data.csv")
#cleaning NAs
dataset$Age=ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
dataset$Salary=ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
#transforming categorical data
dataset$Country=factor(dataset$Country,
levels=c("France","Spain","Germany"),
labels=c(1,2,3))
dataset$Purchased=factor(dataset$Purchased,
levels=c("No","Yes"),
labels=c(0,1))
#divide dataset into training and testing
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# Plantilla para el pre procesado de datos
#import dataset
dataset = read.csv("Data.csv")
#cleaning NAs
dataset$Age=ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
dataset$Salary=ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
#transforming categorical data
dataset$Country=factor(dataset$Country,
levels=c("France","Spain","Germany"),
labels=c(1,2,3))
dataset$Purchased=factor(dataset$Purchased,
levels=c("No","Yes"),
labels=c(0,1))
#divide dataset into training and testing
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
# Plantilla para el pre procesado de datos
#import dataset
dataset = read.csv("Data.csv")
#cleaning NAs
dataset$Age=ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
dataset$Salary=ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
#transforming categorical data
dataset$Country=factor(dataset$Country,
levels=c("France","Spain","Germany"),
labels=c(1,2,3))
dataset$Purchased=factor(dataset$Purchased,
levels=c("No","Yes"),
labels=c(0,1))
#divide dataset into training and testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.8)
training_set = subset(dataset, split==TRUE)
testing_set = subset(dataset, split==FALSE)
setwd("A:/Asus/Documents/UDEMYCOURSES/Machine Learning A to Z/Practicas/26-Model Selection")
# Grid Search
#import dataset
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#divide dataset into training and testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split==TRUE)
testing_set = subset(dataset, split==FALSE)
#Scaling values
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
#Ajustar el clasificador de regresion logistica con el conjunto de entrenamiento
library(e1071)
classifier = svm(formula = Purchased ~ .,
data = training_set,
type = 'C-classification',
kernel = 'radial')
#Prediccion deos resultados del conjunto de testing
#prob_pred = predict(classifier, type = "response", newdata = testing_set[,-3])#solo para logistica
#y_pred = ifelse(prob_pred > 0.5, 1, 0)
#para las demas
y_pred = predict(classifier, newdata = testing_set[,-3])
#Crear la matriz de confusiones
cm = table(testing_set[,3], y_pred)
### APPLY K-FOLD CROSS VALIDATION
library(caret)
folds = createFolds(training_set$Purchased, k = 10)
cv = lapply(folds, function(x){
training_fold = training_set[-x,]
testing_fold = training_set[x,]
classifier = svm(formula = Purchased ~ .,
data = training_fold,
type = 'C-classification',
kernel = 'radial')
y_pred = predict(classifier, newdata = testing_fold[,-3])
#Crear la matriz de confusiones
cm = table(testing_fold[,3], y_pred)
accuracy = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return (accuracy)
})
mean(as.numeric(cv))
#0.913 esa es la media de precisiones de un 91%
sd(as.numeric(cv))
# LA desviacion estandar es 0.063, un 6.3%.... Las predicciones dan un 91 +- 6% de precision
# ===============================================================
#Apply grid search
library(caret)
??train
#Apply grid search
library(caret)
classifier = train( form = Purchased ~ .,
data = training_set,
method = 'svmRadial')
# Grid Search
#import dataset
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
# Convertir a factor
dataset$Purchased=factor(dataset$Purchased,
levels=c("No","Yes"),
labels=c(0,1))
#divide dataset into training and testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split==TRUE)
testing_set = subset(dataset, split==FALSE)
#Scaling values
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
#Ajustar el clasificador de regresion logistica con el conjunto de entrenamiento
library(e1071)
classifier = svm(formula = Purchased ~ .,
data = training_set,
type = 'C-classification',
kernel = 'radial')
#Prediccion deos resultados del conjunto de testing
#prob_pred = predict(classifier, type = "response", newdata = testing_set[,-3])#solo para logistica
#y_pred = ifelse(prob_pred > 0.5, 1, 0)
#para las demas
y_pred = predict(classifier, newdata = testing_set[,-3])
#Crear la matriz de confusiones
cm = table(testing_set[,3], y_pred)
### APPLY K-FOLD CROSS VALIDATION
library(caret)
folds = createFolds(training_set$Purchased, k = 10)
cv = lapply(folds, function(x){
training_fold = training_set[-x,]
testing_fold = training_set[x,]
classifier = svm(formula = Purchased ~ .,
data = training_fold,
type = 'C-classification',
kernel = 'radial')
y_pred = predict(classifier, newdata = testing_fold[,-3])
#Crear la matriz de confusiones
cm = table(testing_fold[,3], y_pred)
accuracy = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return (accuracy)
})
mean(as.numeric(cv))
#0.913 esa es la media de precisiones de un 91%
sd(as.numeric(cv))
# LA desviacion estandar es 0.063, un 6.3%.... Las predicciones dan un 91 +- 6% de precision
# ===============================================================
#Apply grid search
library(caret)
classifier = train( form = Purchased ~ .,
data = training_set,
method = 'svmRadial')
# Grid Search
#import dataset
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
# Convertir a factor
dataset$Purchased=factor(dataset$Purchased)
#divide dataset into training and testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split==TRUE)
testing_set = subset(dataset, split==FALSE)
#Scaling values
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
#Ajustar el clasificador de regresion logistica con el conjunto de entrenamiento
library(e1071)
classifier = svm(formula = Purchased ~ .,
data = training_set,
type = 'C-classification',
kernel = 'radial')
#Prediccion deos resultados del conjunto de testing
#prob_pred = predict(classifier, type = "response", newdata = testing_set[,-3])#solo para logistica
#y_pred = ifelse(prob_pred > 0.5, 1, 0)
#para las demas
y_pred = predict(classifier, newdata = testing_set[,-3])
#Crear la matriz de confusiones
cm = table(testing_set[,3], y_pred)
### APPLY K-FOLD CROSS VALIDATION
library(caret)
folds = createFolds(training_set$Purchased, k = 10)
cv = lapply(folds, function(x){
training_fold = training_set[-x,]
testing_fold = training_set[x,]
classifier = svm(formula = Purchased ~ .,
data = training_fold,
type = 'C-classification',
kernel = 'radial')
y_pred = predict(classifier, newdata = testing_fold[,-3])
#Crear la matriz de confusiones
cm = table(testing_fold[,3], y_pred)
accuracy = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return (accuracy)
})
mean(as.numeric(cv))
#0.913 esa es la media de precisiones de un 91%
sd(as.numeric(cv))
# LA desviacion estandar es 0.063, un 6.3%.... Las predicciones dan un 91 +- 6% de precision
# ===============================================================
#Apply grid search
library(caret)
classifier = train( form = Purchased ~ .,
data = training_set,
method = 'svmRadial')
View(dataset)
View(dataset)
classifier
??svm
classifier$bestTune
library(caret)
folds = createFolds(training_set$Purchased, k = 10)
cv = lapply(folds, function(x){
training_fold = training_set[-x,]
testing_fold = training_set[x,]
classifier = svm(formula = Purchased ~ .,
data = training_fold,
type = 'C-classification',
kernel = 'radial',
sigma = 1.32)
y_pred = predict(classifier, newdata = testing_fold[,-3])
#Crear la matriz de confusiones
cm = table(testing_fold[,3], y_pred)
accuracy = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return (accuracy)
})
mean(as.numeric(cv))
#0.913 esa es la media de precisiones de un 91%
sd(as.numeric(cv))
library(caret)
folds = createFolds(training_set$Purchased, k = 10)
cv = lapply(folds, function(x){
training_fold = training_set[-x,]
testing_fold = training_set[x,]
classifier = svm(formula = Purchased ~ .,
data = training_fold,
type = 'C-classification',
kernel = 'radial',
sigma = 1.32,
cost = 1)
y_pred = predict(classifier, newdata = testing_fold[,-3])
#Crear la matriz de confusiones
cm = table(testing_fold[,3], y_pred)
accuracy = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return (accuracy)
})
mean(as.numeric(cv))
#0.913 esa es la media de precisiones de un 91%
sd(as.numeric(cv))
# LA desviacion estandar es 0.063, un 6.3%.... Las predicciones dan un 91 +- 6% de precision
#Apply grid search
library(caret)
classifier = train( form = Purchased ~ .,
data = training_set,
method = 'svmRadial')
classifier
classifier$bestTune
#Recreate the classifier with the best params... to do this go back to the creation and try it
y_pred = predict(classifier, newdata = testing_set[,-3])
#Crear la matriz de confusiones
cm = table(testing_set[,3], y_pred)
cm
# Grid Search
#import dataset
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
# Convertir a factor
dataset$Purchased=factor(dataset$Purchased)
#divide dataset into training and testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split==TRUE)
testing_set = subset(dataset, split==FALSE)
#Scaling values
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
#Ajustar el clasificador de regresion logistica con el conjunto de entrenamiento
library(e1071)
classifier = svm(formula = Purchased ~ .,
data = training_set,
type = 'C-classification',
kernel = 'radial')
#Prediccion deos resultados del conjunto de testing
#prob_pred = predict(classifier, type = "response", newdata = testing_set[,-3])#solo para logistica
#y_pred = ifelse(prob_pred > 0.5, 1, 0)
#para las demas
y_pred = predict(classifier, newdata = testing_set[,-3])
#Crear la matriz de confusiones
cm = table(testing_set[,3], y_pred)
cm
library(caret)
classifier = train( form = Purchased ~ .,
data = training_set,
method = 'svmRadial')
classifier
classifier$bestTune
#Recreate the classifier with the best params... to do this go back to the creation and try it
y_pred = predict(classifier, newdata = testing_set[,-3])
#Crear la matriz de confusiones
cm = table(testing_set[,3], y_pred)
cm
setwd("A:/Asus/Documents/UDEMYCOURSES/Machine Learning A to Z/Practicas/27-XGBoost")
install.packages("xgboost")
#import dataset
dataset = read.csv("Churn_Modelling.csv")
dataset = dataset[,4:14]
#transforming categorical data
dataset$Geography = as.numeric(factor(dataset$Geography,
levels=c("France","Spain","Germany"),
labels=c(1,2,3)))
dataset$Gender = as.numeric(factor(dataset$Gender,
levels=c("Female","Male"),
labels=c(1,2)))
#divide dataset into training and testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Exited, SplitRatio = 0.80)
training_set = subset(dataset, split==TRUE)
testing_set = subset(dataset, split==FALSE)
#XGBOST DO NOT NEED SCALING VARIABLES
# ADJUST XGBOOST TO THE TRAINING
library(xgboost)
??xgboost
#XGBoost
#import dataset
dataset = read.csv("Churn_Modelling.csv")
dataset = dataset[,4:14]
#transforming categorical data
dataset$Geography = as.numeric(factor(dataset$Geography,
levels=c("France","Spain","Germany"),
labels=c(1,2,3)))
dataset$Gender = as.numeric(factor(dataset$Gender,
levels=c("Female","Male"),
labels=c(1,2)))
#divide dataset into training and testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Exited, SplitRatio = 0.80)
training_set = subset(dataset, split==TRUE)
testing_set = subset(dataset, split==FALSE)
#XGBOST DO NOT NEED SCALING VARIABLES
# ADJUST XGBOOST TO THE TRAINING
library(xgboost)
classifier = xgboost(data = as.matrix(training_set[,-11]),
label = training_set$Exited,
nrounds = 12)
#XGBoost
#import dataset
dataset = read.csv("Churn_Modelling.csv")
dataset = dataset[,4:14]
#transforming categorical data
dataset$Geography = as.numeric(factor(dataset$Geography,
levels=c("France","Spain","Germany"),
labels=c(1,2,3)))
dataset$Gender = as.numeric(factor(dataset$Gender,
levels=c("Female","Male"),
labels=c(1,2)))
#divide dataset into training and testing
library(caTools)
set.seed(123)
split = sample.split(dataset$Exited, SplitRatio = 0.80)
training_set = subset(dataset, split==TRUE)
testing_set = subset(dataset, split==FALSE)
#XGBOST DO NOT NEED SCALING VARIABLES
# ADJUST XGBOOST TO THE TRAINING
library(xgboost)
classifier = xgboost(data = as.matrix(training_set[,-11]),
label = training_set$Exited,
nrounds = 20)
library(caret)
folds = createFolds(training_set$Exited, k = 10)
cv = lapply(folds, function(x){
training_fold = training_set[-x,]
testing_fold = training_set[x,]
classifier = xgboost(data = as.matrix(training_set[,-11]),
label = training_set$Exited,
nrounds = 20)
y_pred = predict(classifier, newdata = as.matrix(testing_fold[,-3]))
y_pred = (y_pred >= 0.5)#Esto se habla con la persona que desea el analisis para estimar un porcentaje
#Crear la matriz de confusiones
cm = table(testing_fold[,11], y_pred)
accuracy = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return (accuracy)
})
mean(as.numeric(cv))
sd(as.numeric(cv))
#Kfold cross validations
library(caret)
folds = createFolds(training_set$Exited, k = 10)
cv = lapply(folds, function(x){
training_fold = training_set[-x,]
testing_fold = training_set[x,]
classifier = xgboost(data = as.matrix(training_set[,-11]),
label = training_set$Exited,
nrounds = 20)
y_pred = predict(classifier, newdata = as.matrix(testing_fold[,-11]))
y_pred = (y_pred >= 0.5)#Esto se habla con la persona que desea el analisis para estimar un porcentaje
#Crear la matriz de confusiones
cm = table(testing_fold[,11], y_pred)
accuracy = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return (accuracy)
})
mean(as.numeric(cv))
sd(as.numeric(cv))
